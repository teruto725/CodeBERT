{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seqレプリケーション\n",
    "\n",
    "seq2seqで結果を出していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akihito/.local/share/virtualenvs/CodeBERT-jLTtsSbs/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import transformers \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "patterns = [\"train\",\"valid\",\"test\"]\n",
    "frases = [\"buggy\",\"fixed\"]\n",
    "filename = \".buggy-fixed.\"\n",
    "RelativePath = \"data/codereview/\"\n",
    "def getPath(pattern_idx: int, frases_idx: int) -> str:\n",
    "    return RelativePath + patterns[pattern_idx] + filename + frases[frases_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "\n",
    "def loadData():\n",
    "    datas = {}\n",
    "    for i in range(len(patterns)):\n",
    "        datas[patterns[i]] = {}\n",
    "        for j in range(len(frases)):\n",
    "            path = getPath(i,j)\n",
    "            with open(path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [line.split(\" \") for line in lines]\n",
    "                datas[patterns[i]][frases[j]] = lines\n",
    "    return datas\n",
    "datas = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: list, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, PreTrainedTokenizer, AutoTokenizer\n",
    "\n",
    "tokenizer = lambda x:  x.split(\" \") # 今回はただのスペース区切り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/codereview/train.buggy-fixed.buggy',\n",
       " 'data/codereview/train.buggy-fixed.fixed']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_filepaths = [getPath(0,0), getPath(0,1)]\n",
    "val_filepaths = [getPath(1,0), getPath(1,1)]\n",
    "test_filepaths = [getPath(2,0), getPath(2,1)]\n",
    "\n",
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', '<eos>', '<pad>', '(', ')']\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/text/stable/vocab.html\n",
    "# https://gist.github.com/nariaki3551/cca40b4011c3b656df9cb1fa487612a7\n",
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "init_token = \"<sos>\"\n",
    "eos_token =\"<eos>\"\n",
    "padding_token  = \"<pad>\"\n",
    "\n",
    "def build_vocab(filepath, tokenizer):\n",
    "  counter = Counter()\n",
    "  with io.open(filepath, encoding=\"utf8\") as f:\n",
    "    for i, string_ in enumerate(f):\n",
    "      counter.update(tokenizer(string_))\n",
    "      # if i == 1000 : break \n",
    "  sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "  ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "  \n",
    "  vocab = torchtext.vocab.vocab(ordered_dict,specials=[init_token, eos_token, padding_token])\n",
    "  \n",
    "  default_index = -1\n",
    "  vocab.set_default_index(default_index)\n",
    "  return vocab\n",
    "    \n",
    "\n",
    "vocab = build_vocab(train_filepaths[0],tokenizer )\n",
    "print(vocab.get_itos()[0:5])\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akihito/.local/share/virtualenvs/CodeBERT-jLTtsSbs/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = asarray(a).shape\n",
      "/Users/akihito/.local/share/virtualenvs/CodeBERT-jLTtsSbs/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1719, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataのtokenize\n",
    "def data_process(filepaths):\n",
    "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "  data = []\n",
    "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
    "    de_tensor_ = torch.tensor([vocab[token] for token in tokenizer(raw_de)],\n",
    "                            dtype=torch.long)\n",
    "    en_tensor_ = torch.tensor([vocab[token] for token in tokenizer(raw_en)],\n",
    "                            dtype=torch.long)\n",
    "    data.append((de_tensor_, de_tensor_))\n",
    "  return data\n",
    "\n",
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)\n",
    "np.shape(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "import torch\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SOS_IDX = vocab['<sos>']\n",
    "EOS_IDX = vocab['<eos>']\n",
    "PAD_IDX = vocab[\"<pad>\"]\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "  src_batch, trg_batch = [], []\n",
    "  for (src_item, trg_item) in data_batch:\n",
    "    src_batch.append(torch.cat([torch.tensor([SOS_IDX]), src_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    trg_batch.append(torch.cat([torch.tensor([SOS_IDX]), trg_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX) #文字列が一定になるようにトークンで埋める（validとtestのみ）\n",
    "  trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "  return src_batch, trg_batch\n",
    "\n",
    "train_iter = DataLoader(train_data, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=generate_batch,\n",
    "                        shuffle=False\n",
    "                      )\n",
    "valid_iter = DataLoader(val_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=generate_batch,\n",
    "                        shuffle=False, \n",
    "                        )\n",
    "test_iter = DataLoader(test_data,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, \n",
    "                       collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([99, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  20,  42,  ...,  42,  20,  20],\n",
      "        [ 51, 146,  30,  ...,  44,  51,  11],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "1\n",
      "torch.Size([97, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  20,  20,  ...,  20,  20,  20],\n",
      "        [ 51,  11, 327,  ...,  30,  30,  24],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "2\n",
      "torch.Size([100, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  71,  ...,  20,  20,  20],\n",
      "        [ 30,  51,  87,  ...,  30, 248,  11],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "3\n",
      "torch.Size([101, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  42,  ...,  20,  42,  42],\n",
      "        [ 30, 118,  51,  ..., 146,  24,  51],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "4\n",
      "torch.Size([100, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  20,  20,  20],\n",
      "        [118,  11,  30,  ...,  44,  30,  19],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "5\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [71, 20, 20,  ..., 20, 42, 20],\n",
      "        [30, 30, 30,  ..., 27, 44, 51],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "6\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 71,  20,  20,  ...,  20,  20,  20],\n",
      "        [ 30,  30,  11,  ..., 169,  51,  30],\n",
      "        ...,\n",
      "        [  2,   1,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "7\n",
      "torch.Size([97, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  20,  42,  20],\n",
      "        [ 28,  19,  51,  ...,  11,  30, 118],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "8\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 42, 42, 24],\n",
      "        [11, 11, 44,  ..., 30, 30, 13],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2, 14],\n",
      "        [ 2,  2,  2,  ...,  2,  2, 15],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  1]])\n",
      "9\n",
      "torch.Size([95, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 42, 20, 20],\n",
      "        [45, 51, 30,  ..., 11, 30, 11],\n",
      "        ...,\n",
      "        [ 2,  2,  6,  ...,  2,  2,  2],\n",
      "        [ 2,  2, 15,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  1,  ...,  2,  2,  2]])\n",
      "10\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [42, 42, 42,  ..., 42, 71, 20],\n",
      "        [30, 11, 51,  ..., 30, 30, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ..., 14,  2,  2],\n",
      "        [ 2,  2,  2,  ..., 15,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  1,  2,  2]])\n",
      "11\n",
      "torch.Size([98, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 71, 20, 71],\n",
      "        [30, 11, 30,  ..., 58, 30, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "12\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 20, 20, 20],\n",
      "        [30, 30, 11,  ..., 51, 30, 11],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  1,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "13\n",
      "torch.Size([96, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  20, 119,  20],\n",
      "        [ 11, 127, 364,  ...,  30,  20,  30],\n",
      "        ...,\n",
      "        [  2,   6,   6,  ...,   2,   2,   2],\n",
      "        [  2,  15,  15,  ...,   2,   2,   2],\n",
      "        [  2,   1,   1,  ...,   2,   2,   2]])\n",
      "14\n",
      "torch.Size([92, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  71,  ...,  20,  20, 119],\n",
      "        [ 30,  28,  44,  ...,  28,  30,  20],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "15\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 20, 20, 20],\n",
      "        [30, 30, 44,  ..., 11, 44, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "16\n",
      "torch.Size([96, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 71, 20,  ..., 20, 42, 42],\n",
      "        [30, 11, 30,  ..., 45, 30, 51],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "17\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 20,  ..., 20, 20, 11],\n",
      "        [95, 11, 87,  ..., 28, 24, 27],\n",
      "        ...,\n",
      "        [ 6,  2,  2,  ...,  2,  2,  2],\n",
      "        [15,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 1,  2,  2,  ...,  2,  2,  2]])\n",
      "18\n",
      "torch.Size([97, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 42,  ..., 71, 20, 20],\n",
      "        [19, 30, 30,  ..., 44, 11, 19],\n",
      "        ...,\n",
      "        [ 2,  2,  6,  ...,  2,  2,  2],\n",
      "        [ 2,  2, 15,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  1,  ...,  2,  2,  2]])\n",
      "19\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 20, 42, 20],\n",
      "        [11, 30, 11,  ..., 30, 51, 24],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  6,  2],\n",
      "        [ 2,  2,  2,  ...,  2, 15,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  1,  2]])\n",
      "20\n",
      "torch.Size([101, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  68,  71,  ...,  20,  42,  20],\n",
      "        [ 30,  13,  30,  ...,  30, 127,  30],\n",
      "        ...,\n",
      "        [  2,   6,   2,  ...,   2,   2,   2],\n",
      "        [  2,  15,   2,  ...,   2,   2,   2],\n",
      "        [  2,   1,   2,  ...,   2,   2,   2]])\n",
      "21\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 42, 20, 71],\n",
      "        [44, 30, 11,  ..., 30, 51, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "22\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  71,  ..., 118,  20,  71],\n",
      "        [ 30,  30,  30,  ...,  30,  30,  30],\n",
      "        ...,\n",
      "        [  2,   6,   2,  ...,   2,   2,   2],\n",
      "        [  2,  15,   2,  ...,   2,   2,   2],\n",
      "        [  2,   1,   2,  ...,   2,   2,   2]])\n",
      "23\n",
      "torch.Size([102, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [42, 42, 42,  ..., 20, 20, 42],\n",
      "        [19, 24, 30,  ..., 28, 44, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "24\n",
      "torch.Size([97, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 20,  ..., 20, 20, 20],\n",
      "        [30, 11, 28,  ..., 44, 24, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "25\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 20,  ..., 20, 42, 20],\n",
      "        [30, 51, 11,  ..., 28, 58, 30],\n",
      "        ...,\n",
      "        [ 2, 14,  2,  ...,  2,  2,  2],\n",
      "        [ 2, 15,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  1,  2,  ...,  2,  2,  2]])\n",
      "26\n",
      "torch.Size([98, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  42,  71,  ...,  20,  30,  42],\n",
      "        [ 44,  30,  44,  ...,  30, 129,  58],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "27\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  20,  20,  42],\n",
      "        [ 11, 217,  19,  ...,  87,  30,  58],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "28\n",
      "torch.Size([101, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 71,  30, 259,  ...,  20,  20,  42],\n",
      "        [ 30,  13,  27,  ...,  30,  24,  11],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "29\n",
      "torch.Size([97, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 71, 20,  ..., 20, 71, 20],\n",
      "        [30, 24, 30,  ..., 19, 30, 11],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "30\n",
      "torch.Size([100, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  71,  20,  ...,  42,  20,  20],\n",
      "        [ 11, 146,  30,  ...,  24,  11,  30],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,  14],\n",
      "        [  2,   2,   2,  ...,   2,   2,  15],\n",
      "        [  2,   2,   2,  ...,   2,   2,   1]])\n",
      "31\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [11, 20, 42,  ..., 20, 20, 20],\n",
      "        [ 3, 30, 30,  ..., 44, 44, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "32\n",
      "torch.Size([101, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  20,  20,  ...,  20,  20,  42],\n",
      "        [ 30,  11, 100,  ...,  11,  87,  44],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,  14,   2],\n",
      "        [  2,   2,   2,  ...,   2,  15,   2],\n",
      "        [  2,   2,   2,  ...,   2,   1,   2]])\n",
      "33\n",
      "torch.Size([92, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  20,  42,  ...,  20,  20,  42],\n",
      "        [ 51,  30,  30,  ...,  51,  30, 151],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   6,   2,   2],\n",
      "        [  2,   2,   2,  ...,  15,   2,   2],\n",
      "        [  2,   2,   2,  ...,   1,   2,   2]])\n",
      "34\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  42,  42, 119],\n",
      "        [ 11, 118,  11,  ...,  30,  51,  71],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   6],\n",
      "        [  2,   2,   2,  ...,   2,   2,  15],\n",
      "        [  2,   2,   2,  ...,   2,   2,   1]])\n",
      "35\n",
      "torch.Size([92, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 11, 20,  ..., 20, 20, 20],\n",
      "        [11, 13, 30,  ..., 11, 68, 27],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  1,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "36\n",
      "torch.Size([102, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 30, 20, 51],\n",
      "        [35, 24, 30,  ..., 13, 11, 27],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "37\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 42,  20,  20,  ...,  20,  20,  20],\n",
      "        [ 30,  24,  24,  ..., 100,  11,  30],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "38\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [71, 42, 71,  ..., 42, 42, 20],\n",
      "        [30, 30, 30,  ..., 44, 44, 24],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "39\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 30,  42,  71,  ...,  20,  87,  20],\n",
      "        [108,  30,  44,  ...,  11,  13,  11],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "40\n",
      "torch.Size([97, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [30, 20, 20,  ..., 42, 20, 71],\n",
      "        [13, 51, 30,  ..., 51, 45, 39],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "41\n",
      "torch.Size([99, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 71,  42,  20,  ...,  20,  20,  20],\n",
      "        [ 44,  11,  30,  ...,  30, 288,  50],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "42\n",
      "torch.Size([100, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 51, 20,  ..., 20, 20, 20],\n",
      "        [24, 24, 11,  ..., 11, 44, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "43\n",
      "torch.Size([92, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [71, 20, 20,  ..., 20, 20, 20],\n",
      "        [30, 78, 11,  ..., 11, 30, 51],\n",
      "        ...,\n",
      "        [14,  1,  2,  ...,  2,  2,  2],\n",
      "        [15,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 1,  2,  2,  ...,  2,  2,  2]])\n",
      "44\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 30,  20,  11,  ...,  20,  42,  20],\n",
      "        [ 13,  30, 165,  ...,  24,  11,  30],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "45\n",
      "torch.Size([102, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [42, 20, 42,  ..., 42, 20, 42],\n",
      "        [58, 11, 44,  ..., 24, 11, 30],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "46\n",
      "torch.Size([101, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 20,  ..., 71, 20, 20],\n",
      "        [24, 30, 11,  ..., 30, 30, 51],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "47\n",
      "torch.Size([98, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 42, 20,  ..., 51, 30, 71],\n",
      "        [51, 30, 30,  ..., 30, 13, 11],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "48\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  71, 119,  20],\n",
      "        [ 30,  11,  51,  ...,  11,  20,  19],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "49\n",
      "torch.Size([96, 32])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [20, 20, 20,  ..., 71, 20, 42],\n",
      "        [30, 35, 35,  ..., 11, 30, 11],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n",
      "50\n",
      "torch.Size([101, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 71,  20,  20,  ...,  42,  42,  20],\n",
      "        [164,  44,  51,  ...,  30,  11,  30],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "51\n",
      "torch.Size([102, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  71,  20,  20],\n",
      "        [ 51,  30,  11,  ..., 149,  11,  35],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "52\n",
      "torch.Size([96, 32])\n",
      "tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 20,  20,  20,  ...,  20,  20,  20],\n",
      "        [ 28,  30, 152,  ...,  58,  11,  51],\n",
      "        ...,\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  2,   2,   2,  ...,   2,   2,   2]])\n",
      "53\n",
      "torch.Size([102, 23])\n",
      "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [42, 20, 20,  ..., 20, 71, 20],\n",
      "        [11, 30, 30,  ..., 30, 30, 51],\n",
      "        ...,\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 2,  2,  2,  ...,  2,  2,  2]])\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(test_iter):\n",
    "    print(i)\n",
    "    print(np.shape(v[0]))\n",
    "    print(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor) -> Tuple[Tensor]:\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attn_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
    "\n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "\n",
    "    def forward(self,\n",
    "                decoder_hidden: Tensor,\n",
    "                encoder_outputs: Tensor) -> Tensor:\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        energy = torch.tanh(self.attn(torch.cat((\n",
    "            repeated_decoder_hidden,\n",
    "            encoder_outputs),\n",
    "            dim = 2)))\n",
    "\n",
    "        attention = torch.sum(energy, dim=2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 dropout: int,\n",
    "                 attention: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "\n",
    "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def _weighted_encoder_rep(self,\n",
    "                              decoder_hidden: Tensor,\n",
    "                              encoder_outputs: Tensor) -> Tensor:\n",
    "\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
    "\n",
    "        return weighted_encoder_rep\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                input: Tensor,\n",
    "                decoder_hidden: Tensor,\n",
    "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
    "                                                          encoder_outputs)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
    "\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "\n",
    "        output = self.out(torch.cat((output,\n",
    "                                     weighted_encoder_rep,\n",
    "                                     embedded), dim = 1))\n",
    "\n",
    "        return output, decoder_hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 device: torch.device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
    "\n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> token\n",
    "        output = trg[0,:]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 234,168 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "OUTPUT_DIM = len(vocab)\n",
    "# ENC_EMB_DIM = 256\n",
    "# DEC_EMB_DIM = 256\n",
    "# ENC_HID_DIM = 64\n",
    "# DEC_HID_DIM = 64\n",
    "# ATTN_DIM = 64\n",
    "# ENC_DROPOUT = 0.5\n",
    "# DEC_DROPOUT = 0.5\n",
    "\n",
    "ENC_EMB_DIM = 32\n",
    "DEC_EMB_DIM = 32\n",
    "ENC_HID_DIM = 64\n",
    "DEC_HID_DIM = 64\n",
    "ATTN_DIM = 8\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "\n",
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = vocab.get_stoi()['<pad>']\n",
    "print(PAD_IDX)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from xml.dom import IndexSizeErr\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: torch.utils.data.DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for _, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: torch.utils.data.DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, (src, trg) in enumerate(iterator):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            \n",
    "            \n",
    "            try :\n",
    "                output = model(src, trg, 0) #turn off teacher forcing\n",
    "                output = output[1:].view(-1, output.shape[-1])\n",
    "                trg = trg[1:].view(-1)\n",
    "                loss = criterion(output, trg)\n",
    "                epoch_loss += loss.item()\n",
    "            except IndexError:\n",
    "                epoch_loss += 6.0\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8034)\n",
      "tensor(3.8728)\n",
      "tensor(3.8966)\n",
      "tensor(3.8900)\n",
      "tensor(3.8461)\n",
      "tensor(3.8030)\n",
      "tensor(3.8402)\n",
      "tensor(3.8518)\n",
      "tensor(3.8581)\n",
      "tensor(3.8942)\n",
      "tensor(3.9364)\n",
      "tensor(3.8332)\n",
      "tensor(3.8467)\n",
      "tensor(3.7304)\n",
      "tensor(3.8657)\n",
      "tensor(3.8294)\n",
      "tensor(3.8591)\n",
      "tensor(3.9461)\n",
      "tensor(3.7984)\n",
      "tensor(3.9274)\n",
      "tensor(3.8311)\n",
      "tensor(3.8309)\n",
      "tensor(3.7930)\n",
      "tensor(3.8659)\n",
      "tensor(3.8607)\n",
      "tensor(3.7834)\n",
      "tensor(3.9385)\n",
      "tensor(3.7227)\n",
      "tensor(3.8326)\n",
      "tensor(3.8697)\n",
      "tensor(3.8936)\n",
      "tensor(3.9279)\n",
      "tensor(3.8558)\n",
      "tensor(3.7682)\n",
      "tensor(3.8465)\n",
      "tensor(3.8076)\n",
      "tensor(3.9159)\n",
      "tensor(3.9159)\n",
      "tensor(3.9290)\n",
      "tensor(3.8520)\n",
      "tensor(3.7966)\n",
      "tensor(3.7377)\n",
      "tensor(3.8773)\n",
      "tensor(3.9467)\n",
      "tensor(3.8310)\n",
      "tensor(3.9085)\n",
      "tensor(3.8582)\n",
      "tensor(3.9527)\n",
      "tensor(3.8115)\n",
      "tensor(3.6687)\n",
      "tensor(3.9372)\n",
      "tensor(3.9138)\n",
      "tensor(3.8672)\n",
      "Epoch: 01 | Time: 3m 45s\n",
      "\tTrain Loss: 3.677 | Train PPL:  39.533\n",
      "\t Val. Loss: 3.894 |  Val. PPL:  49.108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('CodeBERT-jLTtsSbs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb6b705a035926a8e0f5e937dbb38d290ab1b7453ea388834bb2db31240ab868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
